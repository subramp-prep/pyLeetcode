{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a url startUrl and an interface HtmlParser, implement a web crawler to crawl all links that are under the same hostname as startUrl. \n",
    "\n",
    "Returns all urls obtained by your web crawler in any order.\n",
    "\n",
    "Your crawler should:\n",
    "\n",
    "Start from the page: startUrl\n",
    "Call HtmlParser.getUrls(url) to get all urls from a webpage of given url.\n",
    "\n",
    "![example](https://assets.leetcode.com/uploads/2019/08/13/urlhostname.png)\n",
    "\n",
    "Do not crawl the same link twice.\n",
    "Only the links that are under the same hostname as startUrl should be explored by the crawler\n",
    "\n",
    "\n",
    "As shown in the example url above, the hostname is example.org. For simplicity sake, you may assume all urls use http protocol without any port specified.\n",
    "\n",
    "The function interface is defined like this: \n",
    "\n",
    "interface HtmlParser {\n",
    "public:\n",
    "  // Returns a list of urls contained in url .\n",
    "  public List<String> getUrls(String url);\n",
    "}\n",
    "\n",
    "Below there are two examples explaining the functionality of the problem, for custom testing purposes you'll have 3 variables urls, edges and startUrl. Notice that you will only have access to startUrl, while urls and edges are secret to you on the rest of the testcases.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "![e1](https://assets.leetcode.com/uploads/2019/10/23/sample_2_1497.png)\n",
    "\n",
    "```\n",
    "Input:\n",
    "urls = [\n",
    "  \"http://news.yahoo.com\",\n",
    "  \"http://news.yahoo.com/news\",\n",
    "  \"http://news.yahoo.com/news/topics/\",\n",
    "  \"http://news.google.com\",\n",
    "  \"http://news.yahoo.com/us\"\n",
    "]\n",
    "edges = [[2,0],[2,1],[3,2],[3,1],[0,4]]\n",
    "startUrl = \"http://news.yahoo.com/news/topics/\"\n",
    "Output: [\n",
    "  \"http://news.yahoo.com\",\n",
    "  \"http://news.yahoo.com/news\",\n",
    "  \"http://news.yahoo.com/news/topics/\",\n",
    "  \"http://news.yahoo.com/us\"\n",
    "]\n",
    "```\n",
    "Example 2:\n",
    "\n",
    "![e2](https://assets.leetcode.com/uploads/2019/10/23/sample_3_1497.png)\n",
    "\n",
    "```\n",
    "Input: \n",
    "urls = [\n",
    "  \"http://news.yahoo.com\",\n",
    "  \"http://news.yahoo.com/news\",\n",
    "  \"http://news.yahoo.com/news/topics/\",\n",
    "  \"http://news.google.com\"\n",
    "]\n",
    "edges = [[0,2],[2,1],[3,2],[3,1],[3,0]]\n",
    "startUrl = \"http://news.google.com\"\n",
    "Output: [\"http://news.google.com\"]\n",
    "Explanation: The startUrl links to all other pages that do not share the same hostname.\n",
    "```\n",
    "\n",
    "Constraints:\n",
    "\n",
    "1 <= urls.length <= 1000\n",
    "1 <= urls[i].length <= 300\n",
    "startUrl is one of the urls.\n",
    "Hostname label must be from 1 to 63 characters long, including the dots, may contain only the ASCII letters from 'a' to 'z', digits  from '0' to '9' and the hyphen-minus character ('-').\n",
    "The hostname may not start or end with the hyphen-minus character ('-'). \n",
    "See:  https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames\n",
    "You may assume there're no duplicates in url library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "class Solution(object):\n",
    "    def get_hostname(self, url):\n",
    "        start = url.find('//')\n",
    "        if start == -1:\n",
    "            start = 0\n",
    "        else:\n",
    "            start += 2\n",
    "        end = url.find('/', start)\n",
    "        if end == -1:\n",
    "            end = len(url)\n",
    "        return url[start:end]    \n",
    "\n",
    "    def crawl(self, startUrl, htmlParser):\n",
    "        hostname = self.get_hostname(startUrl)\n",
    "        memo = [startUrl]\n",
    "        visited = set()\n",
    "        ans = []\n",
    "\n",
    "        while memo:\n",
    "            next_urls = []\n",
    "            for url in memo:\n",
    "                m = hashlib.sha1()\n",
    "                m.update(url)\n",
    "                if m.digest() in visited or self.get_hostname(url) != hostname:\n",
    "                    continue\n",
    "                ans.append(url)\n",
    "                visited.add(m.digest())\n",
    "                next_urls += htmlParser.getUrls(url)\n",
    "            memo = next_urls\n",
    "\n",
    "        return ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
